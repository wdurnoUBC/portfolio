# Portfolio code appendix 

Please see my primary portfolio website at [wdurno.com](https://wdurno.com).

## [cuda_regression](https://github.com/wdurnoUBC/portfolio/tree/master/cuda_regression) 
This project encodes software for high-dimensional count data regression. Estimation is **GPU-accelerated** with an **R interface**.

## [nbody](https://github.com/wdurnoUBC/portfolio/tree/master/nbody) 
This project encodes software for a [classic N-body simulation](https://en.wikipedia.org/wiki/N-body_simulation) in both **MPI** and **CUDA**. 

## [Java example](https://github.com/wdurnoUBC/portfolio/tree/master/java) 
This project encodes an information management system with a SWING (**Java**) front end and centralized MySQL backend. 

## [Python example](https://github.com/wdurnoUBC/portfolio/tree/master/python) 
This item demonstrates **Python** capabilities. The code is part of an algorithmic arbitrage trading bot. 

## [C++ example](https://github.com/wdurnoUBC/portfolio/tree/master/cpp/fasta_subsetter) 
This item demonstrates basic usage of an STL hash set. 

## [Deep Learning](https://github.com/wdurnoUBC/portfolio/tree/master/deepLearning) 
Items include a convolutional autoencoder, 2-class image classifier, and a Shakespeare-generating recurrent net. Most software is implemented in **Tensorflow**, and also features some Keras.

## [Kaggle competitions](https://github.com/wdurnoUBC/portfolio/blob/master/kaggle) 
Includes two projects. First is a high-dimensional time series regression problem which is solved with **Spark** on **AWS** and **Gradient Boosting**. Spark dataframes illustrate usage of **SQL**. Second is **Naive Bayes** classification. 

## [Math](https://github.com/wdurnoUBC/portfolio/blob/master/regularization_manifolds) 
After showing that many popular regularization methods are equivalent to manifold-constrained estimates, I prove that such constraints reduce estimation error when manifolds are sufficiently unbiased. Interestingly, this means that if discovering a *true* model requires too many parameters, then it really is better to be just a little bit wrong. 

